---
title: "week5notes"
format: html
toc: true
---

# Week 5 Lecture Notes

## Lecture 09 - Modeling Events

### UC berkeley admissions

4526 grad school applications for 1973 UC Berkeley. stratified by department and gender of applicant. We want to find out if there was gender discrimination by admission officers?

Modeling events: events are discrete, unordered outcomes. observations are counts. the unknowns are probabilities (/odds). everything interacts all the time. this is a thing known as "log odds"

For the admissions outcome:

#### Estimand

was there gender discrimination in graduate admissions?

![](images/Screenshot%202025-04-24%20at%2017.22.57.png){width="552"}

department admission rates will vary, so that's in there too.

It's also not the applicant's actual gender that matters, but it would be the perceived gender of the applicant by the referee. we could therefore blind the gender of the applicant from the referee and that could help:

![](images/Screenshot%202025-04-24%20at%2017.24.11.png){width="406"}

In the first model above, what path is "discrimination"? Direct discrimination (G-\>A) would be what's called status-based or taste-based discrimination where referees are biased for or against particular genders. (G-\>D-\>A) is indirect (structural) discrimination where gender might influence interests, etc., which influences department, which influences admission rate. Total discrimination is both paths combined.

![](images/Screenshot%202025-04-24%20at%2017.28.11.png)

we could estimate the total cause of discrimination under relatively minor assumptions, but it's often not what we want - we often care about the particular paths, and those are harder to estimate.

THERE'S ALSO UNOBSERVED CONFOUNDS THAT WE CAN'T FORGET ABOUT - WE'LL COME BACK IN A FUTURE LECTURE.

#### Scientific model

Generative model ![](images/Screenshot%202025-04-24%20at%2017.30.41.png)

```{r}
library(rethinking)
N <- 1000
G <- sample (1:2, size = N, replace = TRUE)
d <-  rbern(N, ifelse(G==1, 0.3, 0.8)) + 1
accept_rate <- matrix(c(0.1,0.3,0.1,0.3), nrow=2)
A <- rbern(N, accept_rate[D,G])
```

![](images/Screenshot%202025-04-24%20at%2017.35.27.png)

then he changes the code to include direct discrimination and we get the same pattern, which is the fundamental issue. from here on out we're going to make a model to piece that out better.

Before we do that,

#### statistical model

we observe counts of events, and from that, we estimate probability (or log-odds) of events. this is like the globe tossing model but we need the "proportionof water" stratified by other variables.

##### Generalized linear models:

linear models are where the expected value is additive combination of parameters.

generalized linear models are where the expected value is some function of an additive combination of parameters

In theory, my interpretation of what's happening below is that GLMs are like linear models but with a link function. the link function exists to constrain the curve to the range that makes sense for our data - so like, if we had a linear model it would extend outside the range from 0-1, but if we are looking for a probability we would want it to stay within, so we use a link function to get there and that makes it a GLM?

![](images/Screenshot%202025-04-29%20at%2008.44.28.png)

![](images/Screenshot%202025-04-29%20at%2008.44.45.png)

Distributions and link functions:

distribuions are relative number of ways to observe data, given assumptions about rates, probabilities, slopes, etc. distributions are matched to constraints on observed variables. link functions are matched to distributions - so we really don't have to worry much about picking them, once we have a distribution for our data the link we should use is pretty obvious.

![](images/Screenshot%202025-04-29%20at%2008.54.11.png)

Bernoulli/binomial models most often use the logit link (log odds) (the log the probability happens divided by the log it doesn't). this lets us attach linear models to discrete events which is very convenient.

now we need priors to go with our funky log scale. the logit link compresses parameter distributions - anything above +4 almost always, anything below -4 almost never

![](images/Screenshot%202025-04-29%20at%2009.12.02.png){width="493"}

##### now let's build the statistical model![](images/Screenshot%202025-04-29%20at%2009.13.33.png)

```{r}
library(rethinking)
N <- 1000 
G <- sample(1:2, size = N, replace = TRUE)
D <- rbern(N, ifelse(G==1, 0.3, 0.8)) +1
accept_rate <-  matrix(c(0.05,0.2,0.1,0.3), nrow=2)
A <-rbern(N, accept_rate[D,G])
```

in the above code, the matrix is because we need gender by department

![](images/Screenshot%202025-04-29%20at%2009.15.51.png)

```{r}
dat_sim <-list (A=A, D=D, G=G)

m1 <- ulam(
  alist(
    A ~bernoulli(p),
    logit(p) <- a[G],
    a[G] ~ normal(0,1)
  ), data=dat_sim, chains=4, cores=4
)

m2 <- ulam(
  alist(
    A ~bernoulli(p),
    logit(p) <- a[G,D],
    matrix[G,D]:a ~ normal(0,1)
  ), data=dat_sim, chains=4, cores=4
)


```

the code above is still pissed at cmdstan for some reason

it should look like below:

![](images/Screenshot%202025-04-29%20at%2009.20.29.png)

hard to interpret the precis on the log odd scale buyt you can see what things are smaller than other things: but you can apply the inverse link function to the coefficients and get them back on the probability scale to interpret them:

![](images/Screenshot%202025-04-29%20at%2009.21.23.png)

#### analyze the data

4526 grad school applications for 1973 berkeley - stratified by department and gender of applicant. we're looking for evidence of gender discrimination

we'll use the same model as before - the data come to us as counts, not as binary 0,1 data - we're going to do binomial regression which is for a count of yes/no data. we'll just change out the word bernoulli for binomial in the analysis. just the aggregated form of long form data:

![](images/Screenshot%202025-04-30%20at%2016.25.06.png)

![](images/Screenshot%202025-04-30%20at%2016.25.31.png)

![](images/Screenshot%202025-04-30%20at%2016.25.54.png)

```{r}
library(rethinking)
data(UCBadmit)
d <-  UCBadmit

dat <- list(
  A = d$admit,
  N = d$applications,
  G = ifelse(d$applicant.gender == "female", 1,2),
  D = as.integer(d$dept)
)

#total effect gender
mG <- ulam(
  alist(
    A ~binomial(N,p),
    a[G] ~ normal(0,1)
  ), data = dat, chains = 4, cores = 4
)
```

total effect code below: men were advantaged

```{r}
post1 <-  extract.samples(mG)
PrA_G1 <- inv_logit(post1$a[,1])
PrA_G2 <-  inv_logit(post1$a[,2])
diff_prob <- PrA_G1 - PrA_G2
dens(digg_prob, lwd = 4, col = 2, xlab = "Gender contrast(probability")
```

direct effects below:

```{r}
post2 <-extract.samples(mGD)
PrA <-  inv_logit(post2$a)
diff_prob_D <-sapply(1:6, function(i)
  Pr[,1,i] - PrA[,2,i])

plot(NULL, xlim= c(-0.2, 0.3), ylim = c(0, 25), xlab = "Gender contrast (probability)", ylab = "Density")
for(i in 1:6) dens(diff_prob_D_[,i], lwd=4, col =1+u, add = TRUE)
```

What is the average direct effect of gender across departments?

depends upon distribution of applications, probability woman/man applies to each department

he then gets into dealing with the direct effect of gender and lost me a bit. has to do with perceived gender in departments - the interventions are going to the same departments, but the counterfactual is that we switch the perceived gender of the applications

![](images/Screenshot%202025-04-30%20at%2017.04.59.png)

![](images/Screenshot%202025-04-30%20at%2017.08.28.png)

the above is post-stratification: description, prediction, and causal inference often require this. it is the re-weighting of estimates for the target population. at a different university, distribution of applications will differ, so predicted consequence of intervention different.

We still don't have evidence for discrimination at this point. big structural effects (women disadvantaged) but different departments have radically different baseline admission rates and because gender has big effect on what department is applied to so - 1) distribution of applications can be a consequence of discrimination but data do not speak to this. 2) confounds are also likely. that's what we'll get into in the next lecture!

## Lecture 10

### Generalized Linear Models

Again, GLMs are where the expected value is some function of an additive combination of parameters. Uniform changes in predictor don't produce uniform changes in the prediction. All predictor variables interact and moderate one another.

Returning to the confounded admissions sample from lecture 9, we're now going to focus on the confounds in the example. The most common one we might think of in this example is the ability of the applicant (u)

![](images/Screenshot%202025-05-22%20at%2016.00.16.png)

```{r}
library(rethinking)
set.seed(12)
N <- 2000
G <- sample(1:2, size = N, replace = TRUE)
u <- rbern(N,0.1)
D <- rbern(N, ifelse(G==1, u*1, 0.75)) +1
p_u0 <- matrix(c(0.1,0.1,0.1,0.3), nrow = 2)
p_u1 <- matrix(c(0.3,0.3,0.5,0.5), nrow = 2)
p_u <- list(p_u0, p_u1)
p <- sapply(1:N, function(i) p_u[[1+u[i]]][D[i],G[i]])
A <- rbern(N,p)
```

![](images/Screenshot%202025-05-22%20at%2016.05.13.png)

in the above, for the total effect of gender, we do not stratify for anything but gender. The second model does stratify by department to separate the direct and indirect effects - you can see that it's harder to intepret the results because it's confounded, but you can make a plot to rescale it:

![](images/Screenshot%202025-05-22%20at%2016.10.04.png)

posterior probability distribution of the probability of admissions is above.

the above situation is apparently an example of collider bias. Stratifying by department opens a non-causal path through u. so you can estimate the total causal effect of Gender, but that isn't what we want (because the interventions are different from the different direct causes) - we can't estimate the DIRECT effect of gender or department from this sample.

more intuitive explanation - high ability of the one gender apply to the discriminatory department anyway, so that gender is on average higher ability in that department than the other gender. So, the high ability of the people of that gender compensates for the discrimination and masks the evidence.

Now, talking about these two papers published last year that come to different conclusions about gender discrimination in the academy:

![](images/Screenshot%202025-05-22%20at%2016.16.12.png)

both are looking at the same population. the paper on the left found an ADVANTAGE for women, the paper on the right found a disadvantage in citation bias form. why? how?

Citation networks - networks in citation between members of the national academy of science. Women are associated with a lower lifetime citation rate. The paper on the left looked at election to the NAS, and found that women were associated with 3-15 times higher election rate, while controlling for citation rate. huhhh?

he thinks:

![](images/Screenshot%202025-05-22%20at%2016.19.06.png){width="377"}

very likely that there are differences in "quality" between members of the NAS. but what we're measuring are proxies for quality, like whether or not they're members or how many citations they have.

![](images/Screenshot%202025-05-22%20at%2016.20.46.png){width="484"}

the thought above is that if men are less likely to be elected, then they must have a higher quality (proxy, citation number) to compensate. If you control for citations, and examine elections to NAS, then G is the "treatment" and C is a post-treatment variable! if women are less likely to be cited because there really is bias, then women are more likely to be elected because they have higher quality than indicated by the citations.

summary of this! we don't want to just produce hyped papers with vague estimands and unwise adjustment sets. we don't want policy to be designed through collider bias! we can do better than that! we honestly can't get at direct effects with this example, and that frequently is the case. it sounds like his conclusion for this (in a discrimination context) is that the best metric for whether it happens or not is the lived experiences of the people who experience it, but that's hard to study quantitatively. ideally we should make clear what our causal assumptions are and also supplement with qualitative data as we're able.

SENSITIVITY ANALYSIS: this is an analysis that is aimed to understand the implications of things we can't measure. Do do this, we assume a confound exists, and model its consequences for different strengths/kinds of influences. we ask how strong the confound has to be to change the conclusions. examples of how that would work in this example is below:

![](images/Screenshot%202025-05-22%20at%2016.35.38.png)

![](images/Screenshot%202025-05-22%20at%2016.37.49.png)

summarizing sensitivity analysis: really important to do. most often in observational studies we can't eliminate possibility of confounding so better to admit it and do sensitivity analysis - vary confound strength over a range and be clear about how your results change. this is the honest and ethical thing to do.

### Dataset on diversity of unique tool types in oceanic society

how is technological complexity related to population size and social structure?

data(Kline)

the typical hypothesis is that population size and contact influence innovations which impact tools:![](images/Screenshot%202025-05-27%20at%2016.47.14.png)

DAG for this:

![](images/Screenshot%202025-05-27%20at%2016.47.43.png){width="485"}

The adjustment set for P is L, we'll also stratify by C to study the interaction

tools we use now: tool number is not binomial, there's no maximum. Poisson distribution here, which has a very high maximum and a low probability of each success (many possible technologies, very few realized in any one place)

![](images/Screenshot%202025-05-27%20at%2016.52.41.png)

![](images/Screenshot%202025-05-27%20at%2016.54.14.png)

above: first he loads the data, then models the relationship between tools and the logarithm of population size because the background theory expects diminishing returns from increasing population size.

then he codes the contact variable, puts it in a list in dat, then runs two models - the intercept only, and the interaction model (alpha and beta bracketed with contact variable for the number of tools and population size to vary by contact rate).

![PSIS is how much worse the model is expected to do out of sample. the model with more parameters has fewer effective parameters. WHY? the penalty measures how much of a difference it makes to the posterior distribution when you drop an individual society.](images/Screenshot%202025-05-27%20at%2016.56.23.png)

![](images/Screenshot%202025-05-27%20at%2017.09.26.png)

I've lost the plot here. we're gonna try to do this model:

![](images/Screenshot%202025-05-27%20at%2016.47.14.png){width="446"}

![](images/Screenshot%202025-05-27%20at%2017.19.50.png)

![](images/Screenshot%202025-05-27%20at%2017.21.05.png)

this one is much better:

![](images/Screenshot%202025-05-27%20at%2017.20.45.png)

In this lecture:

hes tried to present some contexts to transport us into the world of count GLMs. there are ceiling and floor effects (they're "bounded") - as you approach the floor or ceiling of any outcome space the effects get funky?
