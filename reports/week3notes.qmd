---
title: "week3notes"
format: html
---

# Week 3 Lecture Notes

## Lecture 5 - Elemental Confounds

![](images/Screenshot 2025-03-19 at 15.43.55.png)

We're going to talk today about things that happen during the estimator that can cause issues with our estimate.

#### Assocation & Causation

Statistical recipes must defend against confounding, which is a feature of the sample and how we use it that misleads us

![](images/Screenshot 2025-03-19 at 15.45.23.png)

### The Fork

Z is a common cause of X and Y: X & Y are associated because they share the common cause Z. Once stratified by Z, there's no association between X and Y - so, at each level of Z, X and Y are independent (not associated) with one another.

![](images/Screenshot 2025-03-19 at 15.51.30.png){width="465"}

in the above example, you can see that at z values of 0 or 1 X and Y aren't correlated (correlation is out of 1, above 0.3 typically considered correlated)

so, example: why do regions of the USA with higher rates of marriage also have higher rates of divorce? Does marriage cause divorce?

estimand is causal effect of marriage on divorce

![](images/Screenshot 2025-03-19 at 15.56.08.png){width="382"}

(points of the scatter plot not showing up)

![](images/Screenshot 2025-03-19 at 15.57.34.png){width="309"}

![](images/Screenshot 2025-03-19 at 15.59.54.png)

to stratify by A (age at marriage) include as term in linear model

![](images/Screenshot 2025-03-19 at 16.01.10.png)

it is often conveneient to standardize by the mean in linear regression. standardizing means subtract mean and divide by standard deviation - it makes it easier to choose sensible prior and makes computation work better.

![](images/Screenshot 2025-03-19 at 16.04.46.png)

![](images/Screenshot 2025-03-19 at 16.05.33.png){width="346"}

The above code produces this \^ which is bad - they're totally different, the slopes are too extreme,

better priors:

![](images/Screenshot 2025-03-19 at 16.06.47.png)

![](images/Screenshot 2025-03-19 at 16.06.57.png){width="329"}

I think this below is plotting the priors which can be useful?

![](images/Screenshot 2025-03-19 at 16.15.07.png)

The slope is not the causal effect of M - that's often reported but it's not quite right. We're going to do it the principled way which works when we get to more complex models. We do a simulation:

![](images/Screenshot 2025-03-19 at 16.17.01.png)

we play god on M - we delete the arrows going into M to simulate the causal effect of M on D

![](images/Screenshot 2025-03-19 at 16.18.56.png)

the guess from the above is that M on D is a lot smaller than A on D

but you still need to to estimate causal effect of A:

![](images/Screenshot 2025-03-19 at 16.21.01.png){width="451"}

### The Pipe

there was also a Pipe in the above example. let's look at that now.

![](images/Screenshot 2025-03-19 at 16.26.14.png)

statistically the pipe and the fork look the same but causally they're very different so we need to think about them differently. so if we stratified by Z there would be no association between Y and X again - because all the association is transmitted through the effect of X on Z

![](images/Screenshot 2025-03-19 at 16.29.14.png)

EVERYTHING THAT Y KNOWS ABOUT X IS ALREADY KNOWN BY Z.

Example of a pipe:

sometimes ppl think if they're doing a controlled experiment you don't have to bother with all this confound stuff but that's WRONG:

![](images/Screenshot 2025-03-19 at 16.31.43.png){width="495"}

Scientific Model:

![](images/Screenshot 2025-03-19 at 16.32.26.png){width="283"}

then we introduce our treatment: plant could be directly affected by the treatment (hurt or help) but for sure hopefully treatment will affect fungus.

![](images/Screenshot 2025-03-19 at 16.32.55.png){width="375"}

![](images/Screenshot 2025-03-19 at 16.33.53.png){width="413"}

If we want to know the total causal effect of T on H, we DON'T want to stratify by F because we want the total causal effect here to know if we should use the treatment or not.

Sometimes you DO want to stratify by the mediator if you want to know the direct effect - that just isn't the case here!

Another example: POST-TREATMENT BIAS

-   if you stratify by the consequence of the treatment, you can induce post-treatment bias - mislead you that it doesn't work, or that it does work. Rule of thumb: consequences of the treatment should not usually be included in the estimator. there are exceptions to this - things you measure during the experiment sometimes do need to be included.

it can often be dangerous to stratify by

### The Collider

The collider is where Z is jointly caused by both x and y. X and Y are NOT associated, they're independent of one another - but bc they both influence Z, once stratified by Z, X and Y look VERY associated.

![](images/Screenshot 2025-03-20 at 13.22.36.png)

the strong associations could read as causal, so there's a risk of thinking something else is going on, like a fork.

they appear for a variety of reasons:

-   some already arise from selection: suppose there are 200 research grant applications, scored both on newsworthiness and trustworthiness. let's say they're totally unrelated to one another. then we could think about the ones that are funded - if they're sufficiently newsworthy and/or trustworthy they could both be funded. once you stratify by whether they're funded or not there's a strong association between trustworthiness and newsworthiness but in reality the two are not associated:

    ![](images/Screenshot 2025-03-20 at 13.29.47.png)

-   points not showing on graph again

other examples:

-   restaurants survive by having good food or a good location - bad food in good locations

-   actors can succeed by being attractive or by being skilled - attractive actors are less skilled.

endogenous colliders - colliders can also arise through your analysis via endogenous selection: if you stratify by a collider, it creates phantom non-causal associations.

-   example: does age influence happiness? Possible confound here is marital status. suppose age has zero influence on happiness but that both age and happiness influence marital status (happier ppl more likely to get married) (older you are more likely you are to get married)

-   ![](images/Screenshot 2025-03-20 at 13.38.15.png)

### The Descendent

descendent is easy - it's a parasite on the other three: how it behaves is dependent on what it's attached to

![](images/Screenshot 2025-03-20 at 13.41.37.png){width="479"}

because Z is the parent of A, A holds information about Z - so if you stratified by A, it would reduce the measured association between X and Y. but A is actually not causally associated with X or Y

descendents are SUPER COMMON - many measurements are proxies of what we actually want to measure:

-   factor analysis, measurement error, social networks - the things we're measuring are not the thing we're wanting to measure, but they contain information about the unobserved things.

They're both dangerous AND useful.

## Lecture 6 - Good & Bad Controls

# Week 3 Reading Notes

## Chapter 5

## Chapter 6
